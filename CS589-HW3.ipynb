{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPSCI589 Homework 3\n",
    "##### Chang Liu, 3.28.2022\n",
    "\n",
    "## Programming: Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# load data\n",
    "house_data = []\n",
    "\n",
    "# import data, include encoding to ommit BOM  \n",
    "with open('house_votes_84.csv', 'r', encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if len(row) != 0: # skip empty lines\n",
    "            house_data.append(row)\n",
    "\n",
    "house_attributes = house_data[0]\n",
    "# drop attributes name from the data\n",
    "house_data = np.array(house_data[1:]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_tag => entropy\n",
    "def entropy(data):\n",
    "    cnt = list(Counter(data).values())\n",
    "    total = len(data)\n",
    "    return sum([-k/total * math.log(k/total, 2) for k in cnt])\n",
    "\n",
    "def gini(data):\n",
    "    cnt = list(Counter(data).values())\n",
    "    total = len(data)\n",
    "    return 1 - sum([k/total * (k/total) for k in cnt])\n",
    "\n",
    "# house_data(w/ tags)->entropy_of_all_attributes[]\n",
    "def entropy_in_list(data, attr_list, algo):\n",
    "    attr_count = len(data.T) - 1\n",
    "    total_entry = len(data)\n",
    "    ent_list = []\n",
    "    # for each attributes, calculate information gain\n",
    "    for i in range(attr_count):\n",
    "        # skip if not in attr_list\n",
    "        if(not i in attr_list):\n",
    "            ent_list.append(1000) # infinate high entropy\n",
    "            continue\n",
    "        # three possible options are hard coded\n",
    "        # organize data by options\n",
    "        v_tag = {0: [], 1: [], 2: []}\n",
    "        for j in range(len(data)):\n",
    "            v_tag[data[j][i]].append(data[j][-1])\n",
    "        # sum of entropy of each option\n",
    "        ent = sum( len(v_tag[val])/total_entry * algo(v_tag[val]) for val in v_tag )\n",
    "        ent_list.append(ent)\n",
    "    return ent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, isLeaf=False, attr_index=None, tag=None):\n",
    "        self.attr_index = attr_index\n",
    "        self.isLeaf = isLeaf\n",
    "        self.tag = tag\n",
    "        self.possible_options = None\n",
    "        self.option = None\n",
    "        self.children = []\n",
    "\n",
    "    def print_tree(self, indent=0):\n",
    "        ind_str = ' ' * indent\n",
    "        if self.isLeaf:\n",
    "            print( ind_str + \"Leaf:tag\", self.tag, \"vote\", self.option)\n",
    "        else:\n",
    "            print( ind_str + \"Node:\", house_attributes[self.attr_index], \"vote\", self.option)\n",
    "            for child in self.children:\n",
    "                child.print_tree(indent+2)\n",
    "\n",
    "\n",
    "def build_decision_tree(data, attr_list, algo):\n",
    "    # If there are no more attributes that can be tested, return the most common tag\n",
    "    if (not attr_list): # equivelent to len(attr_list) == 0\n",
    "        return Node( isLeaf=True, tag=Counter(data.T[-1]).most_common()[0][0])\n",
    "\n",
    "    # If there are no more data\n",
    "    if (not data.any()):\n",
    "        return Node( isLeaf=True, tag=None)\n",
    "\n",
    "    tags = data.T[-1]\n",
    "    original_entropy = entropy(tags)\n",
    "\n",
    "    # If there is only one tag, return the tag\n",
    "    if (original_entropy == 0):\n",
    "        return Node( isLeaf=True, tag=Counter(tags).most_common()[0][0])\n",
    "    # this subtraction is not necessary, just to be justify the name 'info_gain'\n",
    "    if algo=='gini':\n",
    "        gini_val = entropy_in_list(data, attr_list, gini)\n",
    "        decision_attr = np.argmin(gini_val)\n",
    "    elif algo=='entropy':\n",
    "        info_gain = [original_entropy - ent for ent in entropy_in_list(data, attr_list, entropy)]\n",
    "        decision_attr = np.argmax(info_gain)\n",
    "\n",
    "    # get the index of the attribute with highest information gain\n",
    "    nd = Node( isLeaf=False, attr_index=decision_attr) \n",
    "    # keep track of a majority tag in case the leaf is None\n",
    "    nd.tag = Counter(data.T[-1]).most_common()[0][0]\n",
    "    # remove decision attribute from attr_list\n",
    "    new_attr_list = [x for x in attr_list if x != decision_attr]\n",
    "    # since the option list for all attributes are the same\n",
    "    # so this is hard coded\n",
    "\n",
    "    nd.possible_options = set(data[decision_attr])\n",
    "    # build subtree for each option \n",
    "    for v in nd.possible_options:\n",
    "        # filtered data\n",
    "        new_data = data[data.T[decision_attr] == v]\n",
    "        subtree = build_decision_tree(new_data, new_attr_list, algo) \n",
    "        subtree.option = v\n",
    "        nd.children.append(subtree)\n",
    "    return nd\n",
    "\n",
    "# temporary test data\n",
    "temp_data = house_data[:5, -5:]\n",
    "# temp_data = np.array([[0,0,1,2,2,2,1,0,0,2,0,1,1,2], [0,0,1,1,1,0,1,0,1,1,1,1,1,0]]).T\n",
    "# print(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, node):\n",
    "    for child in node.children:\n",
    "        if data[node.attr_index] == child.option:\n",
    "            if child.isLeaf:\n",
    "                if child.tag == None:\n",
    "                    return node.tag\n",
    "                else:\n",
    "                    return child.tag\n",
    "            else:\n",
    "                return predict(data, child)\n",
    "    return None;\n",
    "\n",
    "def evaluate(data, tree):\n",
    "    correct = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1] == predict(data[i], tree):\n",
    "            correct += 1\n",
    "    return correct / len(data)\n",
    "\n",
    "def dispatch(data, algo, random_state=42):\n",
    "    train, test = train_test_split(data, test_size=0.2, shuffle=True, random_state=random_state)\n",
    "    tree = build_decision_tree(train, list(range(len(house_attributes)-1)), algo)\n",
    "    tree.print_tree()\n",
    "    return evaluate(train, tree), evaluate(test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_train, eval_test = dispatch(temp_data, \"entropy\")\n",
    "\n",
    "print(eval_train, eval_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
