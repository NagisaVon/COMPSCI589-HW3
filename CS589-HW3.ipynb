{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPSCI589 Homework 3\n",
    "##### Chang Liu, 3.28.2022\n",
    "\n",
    "## Programming: Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    '''\n",
    "    list of classes -> entropy\n",
    "    '''\n",
    "    cnt = list(Counter(data).values())\n",
    "    total = len(data)\n",
    "    return sum([-k/total * math.log(k/total, 2) for k in cnt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(data):\n",
    "    cnt = list(Counter(data).values())\n",
    "    total = len(data)\n",
    "    return 1 - sum([k/total * (k/total) for k in cnt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_in_list(data, attr_list, algo):\n",
    "    '''\n",
    "    house_data(w/ tags)->entropy_of_all_attributes[]\n",
    "    '''\n",
    "    attr_count = len(data.T) - 1\n",
    "    total_entry = len(data)\n",
    "    ent_list = []\n",
    "    # for each attributes, calculate information gain\n",
    "    for i in range(attr_count):\n",
    "        # skip if not in attr_list\n",
    "        if(not i in attr_list):\n",
    "            ent_list.append(1000) # infinate high entropy\n",
    "            continue\n",
    "        # three possible classes are hard coded\n",
    "        # organize data by class\n",
    "        v_tag = {0: [], 1: [], 2: []}\n",
    "        for j in range(len(data)):\n",
    "            v_tag[data[j][i]].append(data[j][-1])\n",
    "        # sum of entropy of each class\n",
    "        ent = sum( len(v_tag[val])/total_entry * algo(v_tag[val]) for val in v_tag )\n",
    "        ent_list.append(ent)\n",
    "    return ent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    # tag means different classes, since class is a reserved keyword\n",
    "    def __init__(self, depth, isLeaf=False, attr_index=None, tag=None ):\n",
    "        self.depth = depth\n",
    "        self.attr_index = attr_index\n",
    "        self.isLeaf = isLeaf\n",
    "        self.tag = tag\n",
    "        self.children = []\n",
    "        self.option = None\n",
    "        self.parent = None\n",
    "\n",
    "    def print_tree(self, indent=0):\n",
    "        ind_str = ' ' * indent\n",
    "        if self.isLeaf:\n",
    "            print( ind_str + \"Leaf:CLASS\" , self.tag, \"OPTION\", self.option , \"DEPTH\" , self.depth)\n",
    "        else:\n",
    "            print( ind_str + \"Node:SPLIT_ATTI\" , house_attributes[self.attr_index] , \"OPTION\" , self.option , \"DEPTH\" , self.depth)\n",
    "            for child in self.children:\n",
    "                child.print_tree(indent+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(data, attr_list, algo, _depth=0):\n",
    "    # If there are no more attributes that can be tested, return the most common tag\n",
    "    if (not attr_list): # equivelent to len(attr_list) == 0\n",
    "        return Node( _depth, isLeaf=True, tag=Counter(data.T[-1]).most_common()[0][0])\n",
    "\n",
    "    # If there are no more data\n",
    "    if (not data.any()):\n",
    "        return Node( _depth, isLeaf=True, tag=None)\n",
    "\n",
    "    tags = data.T[-1]\n",
    "    original_entropy = entropy(tags)\n",
    "\n",
    "    # If there is only one tag, return the tag\n",
    "    if (original_entropy == 0):\n",
    "        return Node( _depth, isLeaf=True, tag=Counter(tags).most_common()[0][0])\n",
    "    # this subtraction is not necessary, just to be justify the name 'info_gain'\n",
    "    if algo=='gini':\n",
    "        gini_val = entropy_in_list(data, attr_list, gini)\n",
    "        decision_attr = np.argmin(gini_val)\n",
    "    elif algo=='entropy':\n",
    "        info_gain = [original_entropy - ent for ent in entropy_in_list(data, attr_list, entropy)]\n",
    "        decision_attr = np.argmax(info_gain)\n",
    "\n",
    "    # get the index of the attribute with highest information gain\n",
    "    nd = Node( _depth, isLeaf=False, attr_index=decision_attr ) \n",
    "    # keep track of a majority tag in case the leaf is None\n",
    "    nd.tag = Counter(data.T[-1]).most_common()[0][0]\n",
    "    # remove decision attribute from attr_list\n",
    "    new_attr_list = [x for x in attr_list if x != decision_attr]\n",
    "\n",
    "    nd.possible_options = [0, 1, 2]\n",
    "    # build subtree for each possible option \n",
    "    for v in nd.possible_options:\n",
    "        # filtered data\n",
    "        new_data = data[data.T[decision_attr] == v]\n",
    "        subtree = build_decision_tree(new_data, new_attr_list, algo, _depth+1) \n",
    "        subtree.option = v\n",
    "        nd.children.append(subtree)\n",
    "        subtree.parent = nd\n",
    "\n",
    "    return nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_generate_template_json(attribute_list):\n",
    "    \"\"\"\n",
    "    generate a json names file\n",
    "    \"\"\"\n",
    "    attr_info = []\n",
    "    for i in range(len(attribute_list)):\n",
    "        attr_info.append({'attr_index': i, \\\n",
    "            'attr_name': attribute_list[i], \\\n",
    "            'attr_type': 'categorical', \\\n",
    "            'attr_possible_options': [0, 1, 2]})\n",
    "    with open('temp.json', 'w') as f:\n",
    "        json.dump(attr_info, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(cvsfilename, jsonfilename, classatcolumn=-1, generate_template_json=False): \n",
    "    \"\"\"\n",
    "    load a data file\n",
    "    Arguments:\n",
    "        classatcolumn: where is the class column located, 1 for first column, -1 for last column\n",
    "    Returns:\n",
    "        a data dictionary include all infomation\n",
    "    \"\"\" \n",
    "    data = {'data_only':[], 'class':[], 'possible_classes':[], 'attributes':[], 'attribute_info':[]}\n",
    "    # import data, include encoding to ommit BOM  \n",
    "    original_data = []\n",
    "    with open(cvsfilename, 'r', encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            if len(row) != 0: # skip empty lines\n",
    "                original_data.append(row)\n",
    "    # drop the class attribute from the list\n",
    "    data['attributes'] = original_data[0][:classatcolumn] \n",
    "    data['class'] = original_data[1:][:classatcolumn]\n",
    "    if (classatcolumn == -1):\n",
    "        data['data_only'] = np.array(original_data[1:][:-1]).astype(int)\n",
    "    elif (classatcolumn == 1):\n",
    "        data['data_only'] = np.array(original_data[1:][1:]).astype(int)\n",
    "    if(generate_template_json):\n",
    "        func_generate_template_json(data['attributes'])\n",
    "    # read attribute info from json file\n",
    "    with open(jsonfilename) as json_file:\n",
    "        data['attribute_info'] = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, node):\n",
    "    for child in node.children:\n",
    "        if row[node.attr_index] == child.option:\n",
    "            if child.isLeaf:\n",
    "                if child.tag == None:\n",
    "                    return node.tag\n",
    "                else:\n",
    "                    return child.tag\n",
    "            else:\n",
    "                return predict(row, child)\n",
    "    return None;\n",
    "\n",
    "def evaluate(data, tree):\n",
    "    correct = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1] == predict(data[i], tree):\n",
    "            correct += 1\n",
    "    return correct / len(data)\n",
    "\n",
    "def dispatch(data, algo, random_state=42):\n",
    "    train, test = train_test_split(data, test_size=0.2, shuffle=True, random_state=random_state)\n",
    "    tree = build_decision_tree(train, list(range(len(data['attributes']))), algo)\n",
    "    tree.print_tree()\n",
    "    return evaluate(train, tree), evaluate(test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load house data\n",
    "house_data = load_data(\"datasets/hw3_house_votes_84.csv\", \\\n",
    "    \"datasets/hw3_house_votes_84.json\",\\\n",
    "    classatcolumn=-1,\n",
    "    generate_template_json=False)\n",
    "house_data['possible_classes'] = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 1 2 1]\n",
      " [2 2 1 0 1]\n",
      " [2 2 1 1 0]\n",
      " [2 1 1 2 0]\n",
      " [2 2 2 2 0]]\n"
     ]
    }
   ],
   "source": [
    "# temporary test data\n",
    "temp_data = house_data['data_only'][:5, -5:]\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'entropy' cannot be used to seed a numpy.random.RandomState instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n6/22nb7pzj1hz7zx2w4p7ntjwh0000gn/T/ipykernel_21649/873590165.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhouse_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n6/22nb7pzj1hz7zx2w4p7ntjwh0000gn/T/ipykernel_21649/597713495.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(data, algo, random_state)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_decision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhouse_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2439\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2441\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m     return list(\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \"\"\"\n\u001b[1;32m   1599\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1600\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1601\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         )\n\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m         \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m             \u001b[0;31m# random partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1061\u001b[0m         \u001b[0;34m\"%r cannot be used to seed a numpy.random.RandomState instance\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: 'entropy' cannot be used to seed a numpy.random.RandomState instance"
     ]
    }
   ],
   "source": [
    "eval_train, eval_test = dispatch(temp_data, \"entropy\")\n",
    "\n",
    "print(eval_train, eval_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
